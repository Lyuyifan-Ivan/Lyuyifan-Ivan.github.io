# 天池大赛-新闻文本分类

## 赛题理解
### 数据标签

在数据集中标签的对应的关系如下：{'科技': 0, '股票': 1, '体育': 2, '娱乐': 3, '时政': 4, '社会': 5, '教育': 6, '财经': 7, '家居': 8, '游戏': 9, '房产': 10, '时尚': 11, '彩票': 12, '星座': 13}

### 评价指标

评价标准为类别f1_score的均值，选手提交结果与实际测试集的类别进行对比，结果越大越好

## 解题思路

赛题思路分析：赛题本质是一个文本分类问题，需要根据每句的字符进行分类。但赛题给出的数据是匿名化的，不能直接使用中文分词等操作，这个是赛题的难点。

因此本次赛题的难点是需要对匿名字符进行建模，进而完成文本分类的过程。由于文本数据是一种典型的非结构化数据，因此可能涉及到特征提取和分类模型两个部分。为了减低参赛难度，我们提供了一些解题思路供大家参考：

- 思路1：TF-IDF + 机器学习分类器
  
  直接使用TF-IDF对文本提取特征，并使用分类器进行分类。在分类器的选择上，可以使用SVM、LR、或者XGBoost。

- 思路2：FastText

  FastText是入门款的词向量，利用Facebook提供的FastText工具，可以快速构建出分类器。

- 思路3：WordVec + 深度学习分类器

  WordVec是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可以选择TextCNN、TextRNN或者BiLSTM。

- 思路4：Bert词向量

  Bert是高配款的词向量，具有强大的建模学习能力。

## 数据读取与数据分析

### 数据读取


## FastText模型

论文地址：[Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759)

FastText是一种典型的深度学习词向量的表示方法，它非常简单通过Embedding层将单词映射到稠密空间，然后将句子中所有的单词在Embedding空间中进行平均，进而完成分类操作。

所以FastText是一个三层的神经网络，输入层、隐含层和输出层。

<div align=center>
<img src="fasttext_model.jpg" width="400" height="250" />
</div>

FastText在文本分类任务上，是优于TF-IDF的：
- FastText用单词的Embedding叠加获得的文档向量，将相似的句子分为一类
- FastText学习到的Embedding空间维度比较低，可以快速进行训练

```python
import fasttext
model = fasttext.train_supervised("./train.csv", lr=1.0, wordNgrams=2, verbose=2,
                                  minCount=1, epoch=30, loss='hs')
# f1_score评价指标
pred = [model.predict(x)[0][0].split('__')[-1] for x in train_data.iloc[-20000:]['text']]
# 从训练集取10%作为验证集验证模型得分
print(f1_score(train_label[-20000:].astype('str'), pred, average='macro'))
# 预测测试集标签，并将预测值存储为csv文件
pred = [model.predict(x)[0][0].split('__')[-1] for x in test_data['text']]
pred = pd.DataFrame(pred, columns=['label'])
pred.to_csv("./submit.csv", index=None)
```
当不断增加训练集数量时，FastText的精度也会不断增加5w条训练样本时，验证集得分可以到0.95-0.98左右

### 如何使用验证集调参

在使用TF-IDF和FastText中，有一些模型的参数需要选择，这些参数会在一定程度上影响模型的精度，那么如何选择这些参数呢？
- 通过阅读文档，要弄清楚这些参数的大致含义，那些参数会增加模型的复杂度
- 通过在验证集上进行验证模型精度，找到模型在是否过拟合还是欠拟合

<div align=center>
<img src="2022-03-04.jpg" width="500" height="300" />
</div>

这里我们使用10折交叉验证，每折使用9/10的数据进行训练，剩余1/10作为验证集检验模型的效果。这里需要注意每折的划分必须保证标签的分布与整个数据集的分布一致。

通过10折划分，我们一共得到了10份分布一致的数据，索引分别为0到9，每次通过将一份数据作为验证集，剩余数据作为训练集，获得了所有数据的10种分割。不失一般性，我们选择最后一份完成剩余的实验，即索引为9的一份做为验证集，索引为1-8的作为训练集，然后基于验证集的结果调整超参数，使得模型性能更优。